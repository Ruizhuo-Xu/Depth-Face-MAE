anno_file: ./data/lock3dface.json
max_epochs: 30
lr: 1.e-4
exp_name: vit_mae_finetuning_normal_map_400ep
devices: [3]

dataset:
  train_set:
    name: ImgDataset
    args: 
      anno_file: ${anno_file}
      split: train
  # val_set:
  #   name: ImgDataset
  #   args:
  #     <<: *data_path
  #     split: val
  #     test_mode: True
  batch_size: 1024
  num_workers: 64

model:
  name: ModelForMAE
  args:
    mask_ratio: 0.75
    model_spec:
      name: MAE-ViT
      args:
        img_size: 128
        patch_size: 8
        in_chans: 1
        embed_dim: 384
        depth: 8
        num_heads: 8
        mlp_ratio: 4
        decoder_embed_dim: 256
        decoder_depth: 4
        decoder_num_heads: 8
        norm_pix_loss: True
        pred_normal_map: True
        drop_path: 0.0
    optimizer_spec:
      name: adamw
      args: 
        lr: ${lr}
        weight_decay: 0.05
        betas: [0.9, 0.95]
    lr_sched_spec:
      name: CosineDecayWithWarmup
      args:
        warmup_fraction: 0.05
        max_epochs: ${max_epochs}
        lr: ${lr}
        min_lr: 1.e-9

trainer:
  wandb_logger:
    name: ${exp_name}
    project: Depth-Face-MAE
  checkpoint:
    every_n_epochs: 5
    dirpath: /home/mnt/rz_mnt/depth-face-mae/checkpoints/pretraining
    filename: "{epoch:02d}-{global_step}"
    save_top_k: -1
  args:
    devices: ${devices}
    max_epochs: ${max_epochs}
    log_every_n_steps: 10
    precision: 16-mixed
