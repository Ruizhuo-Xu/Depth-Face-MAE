path: &data_path
  anno_file: ./data/lock3dface.json

epochs: &epochs
  max_epochs: 30

lr_cfg: &lr
  lr: 1.e-4

exp_name: &exp_name
  name: vit_mae_finetuning_normal_map_400ep

dataset:
  train_set:
    name: ImgDataset
    args: 
      <<: *data_path
      split: train
  val_set:
    name: ImgDataset
    args:
      <<: *data_path
      split: val
      test_mode: True
  batch_size: 512
  num_workers: 16

model:
  name: ModelForCls
  args:
    model_spec:
      name: ViT
      args:
        img_size: 128
        patch_size: 16
        in_chans: 1
        embed_dim: 512
        depth: 12
        num_heads: 16
        mlp_ratio: 4
        num_classes: 509
        cls_dropout: 0.9
        drop_path: 0.0
    optimizer_spec:
      name: adamw
      args: 
        <<: *lr
        weight_decay: 0.05
    lr_sched_spec:
      name: CosineDecayWithWarmup
      args:
        warmup_fraction: 0.05
        <<: *epochs
        <<: *lr
        min_lr: 1.e-7
    # lr_decay: 0.85
    ckpt_spec:
      checkpoint_path: /home/mnt/rz_mnt/depth-face-mae/checkpoints/pretraining/vit_mae_pretraining_normal_map_800ep/epoch=199-global_step=0.ckpt
      param_mapping: ["model.->"]
    num_classes: 509
    validation_on_gallery: True
    is_lock3dface: True
    <<:  *data_path

trainer:
  wandb_logger:
    <<: *exp_name
    project: Depth-Face-MAE
  checkpoint:
    every_n_epochs: 10
    dirpath: /home/mnt/rz_mnt/depth-face-mae/checkpoints/fine_tuning
    # filename: "{epoch:02d}-{global_step}"
  args:
    devices: [0, 1]
    <<: *epochs
    log_every_n_steps: 10
    check_val_every_n_epoch: 1
    precision: 16-mixed
