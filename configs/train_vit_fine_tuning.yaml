anno_file: ./data/lock3dface.json
max_epochs: 30
lr: 1.e-4
exp_name: vit_mae_finetuning_normal_map_400ep
devices: [3]

dataset:
  train_set:
    name: ImgDataset
    args: 
      anno_file: ${anno_file}
      split: train
  val_set:
    name: ImgDataset
    args:
      anno_file: ${anno_file}
      split: val
      test_mode: True
  batch_size: 512
  num_workers: 16

model:
  name: ModelForCls
  args:
    model_spec:
      name: ViT
      args:
        img_size: 128
        patch_size: 8
        in_chans: 4
        embed_dim: 384
        depth: 8
        num_heads: 8
        mlp_ratio: 4
        num_classes: 509
        cls_dropout: 0.9
        drop_path: 0.0
        mask_ratio: null
        # arcface_args:
        #   in_features: ${model.args.model_spec.args.embed_dim}
        #   out_features: ${model.args.model_spec.args.num_classes}
        #   s: 30.0
        #   m: 0.5
    optimizer_spec:
      name: adamw
      args: 
        lr: ${lr}
        weight_decay: 0.05
    lr_sched_spec:
      name: CosineDecayWithWarmup
      args:
        warmup_fraction: 0.05
        max_epochs: ${max_epochs}
        lr: ${lr}
        min_lr: 1.e-7
    # lr_decay: 0.85
    ckpt_spec:
      checkpoint_path: /home/mnt/rz_mnt/depth-face-mae/checkpoints/pretraining/vit_mae_tiny_pretraining_lock3d_and_bfm_v3/epoch=19-step=102180.ckpt
      param_mapping: ["model.->"]
    num_classes: ${model.args.model_spec.args.num_classes}
    validation_on_gallery: True
    is_lock3dface: True
    anno_file: ${anno_file}

trainer:
  # wandb_logger:
  #   name: ${exp_name}
  #   project: Depth-Face-MAE
  checkpoint:
    every_n_epochs: 10
    dirpath: /home/mnt/rz_mnt/depth-face-mae/checkpoints/fine_tuning
    # filename: "{epoch:02d}-{global_step}"
  args:
    devices: ${devices}
    max_epochs: ${max_epochs}
    log_every_n_steps: 10
    check_val_every_n_epoch: 1
    precision: 16-mixed
